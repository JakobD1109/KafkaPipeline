# Kafka Scala Avro Producer-Consumer Demo

A real-time data streaming application built with Apache Kafka, Scala, and Avro serialization. This project demonstrates producer-consumer patterns, custom partitioning, load balancing, and failover mechanisms.

## ğŸš€ Features

- **Avro Serialization**: Schema-based data serialization 
- **Custom Partitioner**: Message distribution across partitions
- **Load Balancing**: Multiple consumers processing messages in parallel
- **Failover Support**: Backup consumer for high availability
- **Real-time Processing**: Continuous message streaming and processing

## ğŸ”§ Prerequisites

- **Java**: JDK 11 or higher
- **Scala**: 2.12.18
- **SBT**: 1.x
- **Apache Kafka**: 2.12-3.5.0
- **Apache Zookeeper**: (included with Kafka)

## âš™ï¸ Setup & Installation

### Start Kafka Infrastructure

```bash
# Start Zookeeper (Terminal 1)
cd C:\kafka_2.12-3.5.0
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

# Start Kafka Server (Terminal 2)
cd C:\kafka_2.12-3.5.0
.\bin\windows\kafka-server-start.bat .\config\server.properties

# Create topic with 2 partitions
.\bin\windows\kafka-topics.bat --create --topic demo_sub_topic_4 --bootstrap-server localhost:9092 --partitions 2 --replication-factor 1

# Terminal 3
cd kafka-producer
sbt run
# Select: SimpleKafkaProducerAvro

### Running Consumers
### New Terminal
**Terminal 4 - Primary Consumer (Partition 0):**
```bash
sbt run
# Select: SimpleKafkaConsumer
```

**Terminal 2 - Secondary Consumer (Partition 1):**
```bash
sbt run
# Select: SimpleKafkaConsumer2
```

**Terminal 3 - Backup Consumer (Both Partitions):**
```bash
sbt run
# Select: SimpleKafkaConsumerBackup
```

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Producer â”‚â”€â”€â”€â–¶â”‚   Kafka Topic    â”‚â”€â”€â”€â–¶â”‚   Consumer Group    â”‚
â”‚  (Avro Data)    â”‚    â”‚ demo_sub_topic_4 â”‚    â”‚ "load-balance-group"â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                     â”‚
â”‚ CustomPartitionerâ”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚      â†“          â”‚    â”‚ â”‚ Partition 0 â”‚  â”‚    â”‚ â”‚   Consumer 1    â”‚ â”‚
â”‚ key1â†’Partition 0â”‚    â”‚ â”‚ key1, key3  â”‚  â”‚    â”‚ â”‚  (Partition 0)  â”‚ â”‚
â”‚ key2â†’Partition 1â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ key3â†’Partition 0â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ key4â†’Partition 1â”‚    â”‚ â”‚ Partition 1 â”‚  â”‚    â”‚ â”‚   Consumer 2    â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚ key2, key4  â”‚  â”‚    â”‚ â”‚  (Partition 1)  â”‚ â”‚
                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚   Backup Consumer   â”‚
                                               â”‚ "backup-group"      â”‚
                                               â”‚ (Failover Support)  â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Data Flow

1. **Producer** creates Student objects with Avro schema
2. **CustomPartitioner** routes messages:
   - `key1, key3` â†’ Partition 0
   - `key2, key4` â†’ Partition 1
3. **Consumer Group** load balances:
   - Consumer 1 processes Partition 0
   - Consumer 2 processes Partition 1
4. **Backup Consumer** monitors and activates on failure

## ğŸ› ï¸ Configuration

### Producer Settings
- **Serializers**: String key, ByteArray value
- **Partitioner**: CustomPartitioner for balanced distribution
- **Topic**: demo_sub_topic_4

### Consumer Settings
- **Deserializers**: String key, ByteArray value
- **Group ID**: load-balance-group (for load balancing)
- **Auto Offset Reset**: earliest
- **Enable Auto Commit**: true

## ğŸŒŸ Future Enhancements

- [ ] Add real-time API data ingestion
- [ ] Implement Python consumer for data processing
- [ ] Add Kafka Streams for event processing
- [ ] Integrate with monitoring tools (JMX, Prometheus)

## ğŸ“ Contact

Jakob Drews - jakobdrews97@gmail.com

Project Link: [https://github.com/JakobD1109/KafkaPipeline]
